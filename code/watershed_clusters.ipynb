{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlAntonov/poultry/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22watershed_clusters_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXQScVVqAwXe"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uncXjGPH-sOw"
      },
      "outputs": [],
      "source": [
        "# download good sample image\n",
        "!gdown --id 17uDkD5dt5JIr0z7nER0TJ3--_I-7FwQ8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vlf_lbYGBkHx"
      },
      "outputs": [],
      "source": [
        "# download our video\n",
        "!gdown --id 1r1E2NZ9r3AodYm-7PYR4mVUthRfb7fNa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOWU69A8Camx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.measure import regionprops, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMZjROZ9CpnQ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ-_MSmJB5aO"
      },
      "outputs": [],
      "source": [
        "def get_video_frame(video):\n",
        "  cap = cv2.VideoCapture(video)\n",
        "  ret, frame = cap.read()\n",
        "\n",
        "  return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hcCmlC7UbmI"
      },
      "outputs": [],
      "source": [
        "def get_video_frame_num(video, frame_num):\n",
        "    cap = cv2.VideoCapture(video)\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num-1)\n",
        "    res, frame = cap.read()\n",
        "\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9oo6hUYCXP_"
      },
      "outputs": [],
      "source": [
        "def cluster_image(img):\n",
        "  gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\t\n",
        "  ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "\n",
        "  # noise removal\n",
        "  kernel = np.ones((3,3),np.uint8)\n",
        "  opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
        "  # sure background area\n",
        "  sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
        "  # Finding sure foreground area\n",
        "  dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
        "  ret, sure_fg = cv2.threshold(dist_transform, 0.9*dist_transform.max(),255,0)\n",
        "  # Finding unknown region\n",
        "  sure_fg = np.uint8(sure_fg)\n",
        "  unknown = cv2.subtract(sure_bg,sure_fg)\n",
        "  # Marker labelling\n",
        "  ret, markers = cv2.connectedComponents(sure_fg)\n",
        "  # Add one to all labels so that sure background is not 0, but 1\n",
        "  markers = markers+1\n",
        "  # Now, mark the region of unknown with zero\n",
        "  markers[unknown==255] = 0\n",
        "  markers = cv2.watershed(img,markers)\n",
        "  \n",
        "  regions = regionprops(markers)\n",
        "  for r in regions:\n",
        "    print(r.area)\n",
        "  # regions = [r for r in regions if r.area > 5]\n",
        "  print('Number of clusters:', len(regions) - 1)\n",
        "\n",
        "  cluster_img = img.copy()\n",
        "  cluster_img[markers == -1] = [255,0,0]\n",
        "  cluster_img[markers != -1] = [255,255,255]\n",
        "  return cluster_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SF3Dtl2rD-Es"
      },
      "outputs": [],
      "source": [
        "def resize_image(img, scale_percent=50):\n",
        "  width = int(img.shape[1] * scale_percent / 100)\n",
        "  height = int(img.shape[0] * scale_percent / 100)\n",
        "  dim = (width, height)\n",
        "    \n",
        "  return cv2.resize(img, dim, interpolation = cv2.INTER_AREA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7at8XyYGjsp9"
      },
      "outputs": [],
      "source": [
        "def crop_image(img):\n",
        "  # return img[int(img.shape[0]/6):int(3*img.shape[0]/6), int(img.shape[1]/3):int(2*img.shape[1]/3)]\n",
        "  return img[int(img.shape[0]/3):int(2*img.shape[0]/3), int(img.shape[1]/3):int(2*img.shape[1]/3)]\n",
        "  # return img[0:img.shape[0], 0:int(3*img.shape[1]/4)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJxDJBGGECAR"
      },
      "outputs": [],
      "source": [
        "def increase_image_contrast(img):\n",
        "  import cv2\n",
        "  import numpy as np\n",
        "\n",
        "  # converting to LAB color space\n",
        "  lab= cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "  l_channel, a, b = cv2.split(lab)\n",
        "\n",
        "  # Applying CLAHE to L-channel\n",
        "  # feel free to try different values for the limit and grid size:\n",
        "  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "  cl = clahe.apply(l_channel)\n",
        "\n",
        "  # merge the CLAHE enhanced L-channel with the a and b channel\n",
        "  limg = cv2.merge((cl,a,b))\n",
        "\n",
        "  # Converting image from LAB Color model to BGR color spcae\n",
        "  enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "  return enhanced_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkXQWpJ9Mmk0"
      },
      "outputs": [],
      "source": [
        "def plot_four(img1, img2, img3, img4):\n",
        "  fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(16,9))\n",
        "  ax = axes.ravel()\n",
        "\n",
        "  ax[0].imshow(img1)\n",
        "  ax[0].set_title('Base frame')\n",
        "  ax[1].imshow(img2)\n",
        "  ax[1].set_title('Crop')\n",
        "  ax[2].imshow(img3)\n",
        "  ax[2].set_title('Denoising')\n",
        "  ax[3].imshow(img4)\n",
        "  ax[3].set_title('Clusters')\n",
        "\n",
        "  for a in ax:\n",
        "    a.set_axis_off()\n",
        "\n",
        "  fig.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8Z07VNACkIu"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('/content/water_coins.jpg')\n",
        "# print('Image Dimensions :', img.shape)\n",
        "img2 = cluster_image(img)\n",
        "\n",
        "plot_four(img, img, img2, img2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F2rQSouDTcV"
      },
      "outputs": [],
      "source": [
        "for i in range(3955, 3995, 40):\n",
        "  img1 = get_video_frame_num('/content/20210316-100031.mp4', i)\n",
        "  img2 = crop_image(img1)\n",
        "  img3 = cv2.fastNlMeansDenoisingColored(img2,None,20,20,7,21)\n",
        "  # img = increase_image_contrast(img)\n",
        "  img4 = cluster_image(img3)\n",
        "\n",
        "  plot_four(img1, img2, img3, img4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJJfHF1AjP0-"
      },
      "outputs": [],
      "source": [
        "img2 = []\n",
        "num_image = 8\n",
        "frame_num = 3955\n",
        "gap = 5\n",
        "for i in range(frame_num-gap*num_image, frame_num+gap*num_image+1, gap):\n",
        "  img1 = get_video_frame_num('/content/20210316-100031.mp4', i)\n",
        "  img2.append(crop_image(img1))\n",
        "print(len(img2))\n",
        "img3 = cv2.fastNlMeansDenoisingColoredMulti(img2,num_image,num_image*2+1,None,20,20,7,21) # (img2,11,5)\n",
        "img4 = cluster_image(img3)\n",
        "\n",
        "plot_four(img1, img2[2], img3, img4)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
