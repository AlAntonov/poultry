{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1-shN0utNBW0uGqt5yYLBkR8qiFhRQyGJ",
      "authorship_tag": "ABX9TyPyt+fzsRj7OXB1kr0fsJuy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlAntonov/poultry/blob/main/get_number_of_clusters_dynamic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "tyzikHz-i1VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown"
      ],
      "metadata": {
        "id": "tLVYYRSrsEi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download good sample image\n",
        "!gdown --id 17uDkD5dt5JIr0z7nER0TJ3--_I-7FwQ8"
      ],
      "metadata": {
        "id": "FaMHXXnbsHuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download our video\n",
        "!gdown --id 1r1E2NZ9r3AodYm-7PYR4mVUthRfb7fNa"
      ],
      "metadata": {
        "id": "3nsqTVkwsKGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from skimage import morphology\n",
        "from skimage.feature import peak_local_max\n",
        "from skimage.segmentation import watershed\n",
        "from scipy import ndimage\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "from os import remove\n",
        "import pandas as pd\n",
        "import ntpath\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from scipy import ndimage as ndi"
      ],
      "metadata": {
        "id": "sqBXAUZSuQeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "fdV-XK01ICmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjd-820SKdEq"
      },
      "outputs": [],
      "source": [
        "def get_number_of_clusters(image, size_threshold, number_of_clusters_list):\n",
        "  height, width = image.shape[:2]\n",
        "  # introduce a scale factor in order to operate with smaller resolutions\n",
        "  scale_factor = height * width / (1280 * 720)\n",
        "  \n",
        "  # the filtering stage of meanshift segmentation\n",
        "  # output is the filtered \"posterized\" image with color\n",
        "  # gradients and fine-grain texture flattened\n",
        "  aperture = 15 # aperture of median blur filter (depends on conditions)\n",
        "  image_mean = cv2.medianBlur(image, aperture)\n",
        "  # convert the mean shift image to grayscale, then apply\n",
        "  # Otsu's thresholding\n",
        "  image_gray = cv2.cvtColor(image_mean, cv2.COLOR_BGR2GRAY)\n",
        "  threshold = cv2.threshold(image_gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
        "\n",
        "  # compute the exact Euclidean distance from every binary\n",
        "  # pixel to the nearest zero pixel, then find peaks in this\n",
        "  # distance map\n",
        "  distance_map = ndimage.distance_transform_edt(threshold)\n",
        "  # here min_distance is also empirical parameter\n",
        "  local_max = peak_local_max(distance_map, indices=False, min_distance=int(20 * scale_factor), labels=threshold)\n",
        "\n",
        "  distance = ndi.distance_transform_edt(image)\n",
        "\n",
        "  # perform a connected component analysis on the local peaks,\n",
        "  # using 8-connectivity, then appy the Watershed algorithm\n",
        "  markers = ndimage.label(local_max, structure=np.ones((3, 3)))[0]\n",
        "  labels = watershed(-distance_map, markers, mask=threshold)\n",
        "\n",
        "  # remove noise labels with size < 400 (empirical parameter also)\n",
        "  size_threshold = size_threshold\n",
        "  labels = morphology.remove_small_objects(labels, size_threshold * scale_factor)\n",
        "  number_of_clusters = len(np.unique(labels)) - 1;\n",
        "  number_of_clusters_list.append(number_of_clusters)\n",
        "  # print(number_of_clusters)\n",
        "  \n",
        "  fig, axes = plt.subplots(ncols=3, figsize=(27, 9))#, sharex=True, sharey=True)\n",
        "  ax = axes.ravel()\n",
        "\n",
        "  ax[0].imshow(image, cmap=plt.cm.gray)\n",
        "  ax[0].set_title('Overlapping objects')\n",
        "  # ax[1].imshow(-distance, cmap=plt.cm.gray)\n",
        "  # ax[1].set_title('Distances')\n",
        "  ax[1].imshow(labels, cmap=plt.cm.nipy_spectral)\n",
        "  ax[1].set_title('Separated objects')\n",
        "  ax[2].plot(number_of_clusters_list, 'b')\n",
        "  ax[2].set_title('Time frame')\n",
        "\n",
        "  # for a in ax:\n",
        "  #  a.set_axis_off()\n",
        "\n",
        "  fig.tight_layout()\n",
        "  display.display(plt.gcf())\n",
        "  display.clear_output(wait=True)\n",
        "  \n",
        "  return number_of_clusters_list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_frame_num(video, frame_num):\n",
        "    cap = cv2.VideoCapture(video)\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num-1)\n",
        "    res, frame = cap.read()\n",
        "\n",
        "    return frame"
      ],
      "metadata": {
        "id": "Mw4X7pIqgFhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_image(img):\n",
        "  # return img[int(img.shape[0]/6):int(3*img.shape[0]/6), int(img.shape[1]/3):int(2*img.shape[1]/3)]\n",
        "  # return img[int(img.shape[0]/3):int(2*img.shape[0]/3), int(img.shape[1]/3):int(2*img.shape[1]/3)]\n",
        "  return img[int(img.shape[0]/6):int(5*img.shape[0]/6), int(2*img.shape[1]/4):int(3*img.shape[1]/4)]"
      ],
      "metadata": {
        "id": "WTXJv87hNhSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show dynamics\n",
        "number_of_clusters_list = []\n",
        "start = 4555\n",
        "step = 5\n",
        "frame_quantity = 60\n",
        "size_threshold = 3200\n",
        "\n",
        "for frame_num in range(start, start+frame_quantity*step, step):\n",
        "  image = get_video_frame_num('/content/20210316-100031.mp4', frame_num)\n",
        "  image = crop_image(image)\n",
        "  number_of_clusters_list = get_number_of_clusters(image, size_threshold, number_of_clusters_list)"
      ],
      "metadata": {
        "id": "i_xKVWaVtxMK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
